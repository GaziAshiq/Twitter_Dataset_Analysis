{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-29T19:30:48.741875900Z",
     "start_time": "2023-05-29T19:30:48.732003700Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# load the pre-trained spaCy model for English\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T19:30:50.303659Z",
     "start_time": "2023-05-29T19:30:49.890298400Z"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "# conda install -c conda-forge spacy\n",
    "# python -m spacy download en_core_web_sm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# load twitter_dataset\n",
    "import pandas as pd\n",
    "\n",
    "tweets = pd.read_csv('twitter_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T19:32:34.776343600Z",
     "start_time": "2023-05-29T19:32:34.732305700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# process each tweet text and extract entities\n",
    "entities = []\n",
    "for tweet in tweets['Text']:\n",
    "    doc = nlp(tweet)\n",
    "    entities.append([ent.text for ent in doc.ents])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T19:34:29.373355200Z",
     "start_time": "2023-05-29T19:33:31.736315500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: [], Frequency: 2814\n",
      "Entity: ['Republican'], Frequency: 108\n",
      "Entity: ['American'], Frequency: 97\n",
      "Entity: ['four'], Frequency: 92\n",
      "Entity: ['half'], Frequency: 89\n",
      "Entity: ['Democrat'], Frequency: 89\n",
      "Entity: ['Congress'], Frequency: 88\n",
      "Entity: ['two'], Frequency: 80\n",
      "Entity: ['first'], Frequency: 79\n",
      "Entity: ['second'], Frequency: 78\n"
     ]
    }
   ],
   "source": [
    "# Count the frequency of each entity\n",
    "entity_freq = {}\n",
    "for entity in entities:\n",
    "    entity_str = str(entity)  # Convert the entity tuple to a string\n",
    "    if entity_str in entity_freq:\n",
    "        entity_freq[entity_str] += 1\n",
    "    else:\n",
    "        entity_freq[entity_str] = 1\n",
    "\n",
    "# Sort the entities by frequency in descending order\n",
    "sorted_entities = sorted(entity_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the top entities and their frequencies\n",
    "num_entities = 10  # Specify the number of top entities to display\n",
    "for entity, freq in sorted_entities[:num_entities]:\n",
    "    print(f'Entity: {entity}, Frequency: {freq}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T19:39:04.899985800Z",
     "start_time": "2023-05-29T19:39:04.857569200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
